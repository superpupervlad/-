{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab_5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Zpq4QOU5Wg-H",
        "i_7DyyXRWg-K",
        "_JewKs4XU-so",
        "5yiLk1P_xYQ2",
        "VlWxW3e9Wg-m",
        "D39SSh0zWg-r",
        "rhVrgkSaWg_K",
        "XsRf9T_SWg_U",
        "ylKZG2MwWg_f",
        "9hedBdcYWhAH",
        "JrqW55jgWhAR",
        "5QYTwyMtWhAZ",
        "DbJrUpARWhAd",
        "MI18l-l9WhAk",
        "1wrEGqBSWhAr",
        "gStgBJy2WhAx"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHX9p5jfTySS"
      },
      "source": [
        "## Задание 5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EnHNZtbXlH0"
      },
      "source": [
        "Набор данных тут: https://github.com/sismetanin/rureviews, также есть в папке [Data](https://drive.google.com/drive/folders/1YAMe7MiTxA-RSSd8Ex2p-L0Dspe6Gs4L). Те, кто предпочитает работать с английским языком, могут использовать набор данных `sms_spam`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJox-LoonoPx"
      },
      "source": [
        "Применим полученные навыки и решим задачу анализа тональности отзывов. \n",
        "\n",
        "Нужно повторить весь пайплайн от сырых текстов до получения обученной модели.\n",
        "\n",
        "Обязательные шаги предобработки:\n",
        "1. токенизация\n",
        "2. приведение к нижнему регистру\n",
        "3. удаление стоп-слов\n",
        "4. лемматизация\n",
        "5. векторизация (с настройкой гиперпараметров)\n",
        "6. построение модели\n",
        "7. оценка качества модели\n",
        "\n",
        "Обязательно использование векторайзеров:\n",
        "1. мешок n-грамм (диапазон для n подбирайте самостоятельно, запрещено использовать только униграммы).\n",
        "2. tf-idf ((диапазон для n подбирайте самостоятельно, также нужно подбирать параметры max_df, min_df, max_features)\n",
        "3. символьные n-граммы (диапазон для n подбирайте самостоятельно)\n",
        "\n",
        "В качестве классификатора нужно использовать наивный байесовский классификатор. \n",
        "\n",
        "Для сравнения векторайзеров между собой используйте precision, recall, f1-score и accuracy. Для этого сформируйте датафрейм, в котором в строках будут разные векторайзеры, а в столбцах разные метрики качества, а в  ячейках будут значения этих метрик для соответсвующих векторайзеров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkrpchMF95XG",
        "outputId": "c441e504-4839-4c22-e27a-641899677028"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.util import ngrams, bigrams, trigrams\n",
        "from pymystem3 import Mystem\n",
        "from sklearn.metrics import * \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from ngram import NGram\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/vlad/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /home/vlad/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/vlad/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVLKjUpA95XI"
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/sismetanin/rureviews/blob/master/women-clothing-accessories.3-class.balanced.csv\\?raw\\=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fnlpGj7X95XJ",
        "outputId": "dbbdeae6-204a-42b7-9aad-b49624f3d0a3"
      },
      "source": [
        "df = pd.read_csv(\"women-clothing-accessories.3-class.balanced.csv?raw=true\", sep=\"\\t\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  качество плохое пошив ужасный (горловина напер...  negative\n",
              "1  Товар отдали другому человеку, я не получила п...  negative\n",
              "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
              "3  товар не пришел, продавец продлил защиту без м...  negative\n",
              "4      Кофточка голая синтетика, носить не возможно.  negative"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D-FR5Gj95XJ"
      },
      "source": [
        "### Токенизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rmWS47io95XK",
        "outputId": "56f804c7-6590-4e7e-828d-1e75f6dd9564"
      },
      "source": [
        "df['tokenized'] = df['review'].transform(word_tokenize)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[качество, плохое, пошив, ужасный, (, горловин...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[Товар, отдали, другому, человеку, ,, я, не, п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[Ужасная, синтетика, !, Тонкая, ,, ничего, общ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[товар, не, пришел, ,, продавец, продлил, защи...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
              "      <td>negative</td>\n",
              "      <td>[Кофточка, голая, синтетика, ,, носить, не, во...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  качество плохое пошив ужасный (горловина напер...  negative   \n",
              "1  Товар отдали другому человеку, я не получила п...  negative   \n",
              "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
              "3  товар не пришел, продавец продлил защиту без м...  negative   \n",
              "4      Кофточка голая синтетика, носить не возможно.  negative   \n",
              "\n",
              "                                           tokenized  \n",
              "0  [качество, плохое, пошив, ужасный, (, горловин...  \n",
              "1  [Товар, отдали, другому, человеку, ,, я, не, п...  \n",
              "2  [Ужасная, синтетика, !, Тонкая, ,, ничего, общ...  \n",
              "3  [товар, не, пришел, ,, продавец, продлил, защи...  \n",
              "4  [Кофточка, голая, синтетика, ,, носить, не, во...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ0il4mX95XK"
      },
      "source": [
        "### Приведение к нижнему регистру\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fROS1jPs95XL",
        "outputId": "963f79f2-aab5-4a69-bc29-1731b33a92c0"
      },
      "source": [
        "df['tokenized'] = df['tokenized'].transform(lambda t: [word.lower() for word in t])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[качество, плохое, пошив, ужасный, (, горловин...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[товар, отдали, другому, человеку, ,, я, не, п...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[ужасная, синтетика, !, тонкая, ,, ничего, общ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[товар, не, пришел, ,, продавец, продлил, защи...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
              "      <td>negative</td>\n",
              "      <td>[кофточка, голая, синтетика, ,, носить, не, во...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  качество плохое пошив ужасный (горловина напер...  negative   \n",
              "1  Товар отдали другому человеку, я не получила п...  negative   \n",
              "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
              "3  товар не пришел, продавец продлил защиту без м...  negative   \n",
              "4      Кофточка голая синтетика, носить не возможно.  negative   \n",
              "\n",
              "                                           tokenized  \n",
              "0  [качество, плохое, пошив, ужасный, (, горловин...  \n",
              "1  [товар, отдали, другому, человеку, ,, я, не, п...  \n",
              "2  [ужасная, синтетика, !, тонкая, ,, ничего, общ...  \n",
              "3  [товар, не, пришел, ,, продавец, продлил, защи...  \n",
              "4  [кофточка, голая, синтетика, ,, носить, не, во...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q26vwke795XL"
      },
      "source": [
        "### Удаление стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GlngynQ795XM",
        "outputId": "bbd844bb-a346-45c5-bf34-10e88f9db4ee"
      },
      "source": [
        "sw = set(stopwords.words('russian'))\n",
        "df['tokenized'] = df['tokenized'].transform(lambda t: [word for word in t if word not in sw])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[качество, плохое, пошив, ужасный, (, горловин...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[товар, отдали, другому, человеку, ,, получила...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[ужасная, синтетика, !, тонкая, ,, общего, пре...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[товар, пришел, ,, продавец, продлил, защиту, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
              "      <td>negative</td>\n",
              "      <td>[кофточка, голая, синтетика, ,, носить, возмож...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  качество плохое пошив ужасный (горловина напер...  negative   \n",
              "1  Товар отдали другому человеку, я не получила п...  negative   \n",
              "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
              "3  товар не пришел, продавец продлил защиту без м...  negative   \n",
              "4      Кофточка голая синтетика, носить не возможно.  negative   \n",
              "\n",
              "                                           tokenized  \n",
              "0  [качество, плохое, пошив, ужасный, (, горловин...  \n",
              "1  [товар, отдали, другому, человеку, ,, получила...  \n",
              "2  [ужасная, синтетика, !, тонкая, ,, общего, пре...  \n",
              "3  [товар, пришел, ,, продавец, продлил, защиту, ...  \n",
              "4  [кофточка, голая, синтетика, ,, носить, возмож...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S94T04tg95XM"
      },
      "source": [
        "### Лемматизация\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mn75FPtI95XM",
        "outputId": "3f574939-bc73-4f22-e336-873d6bbebd19"
      },
      "source": [
        "m = Mystem()\n",
        "df['tokenized'] = df['tokenized'].transform(lambda t: ''.join(m.lemmatize(' '.join(t))))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
              "      <td>negative</td>\n",
              "      <td>качество плохой пошив ужасный ( горловина напе...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
              "      <td>negative</td>\n",
              "      <td>товар отдавать другой человек , получать посыл...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
              "      <td>negative</td>\n",
              "      <td>ужасный синтетика ! тонкий , общий представлят...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
              "      <td>negative</td>\n",
              "      <td>товар приходить , продавец продлять защита мой...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
              "      <td>negative</td>\n",
              "      <td>кофточка голый синтетика , носить возможно .\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  качество плохое пошив ужасный (горловина напер...  negative   \n",
              "1  Товар отдали другому человеку, я не получила п...  negative   \n",
              "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative   \n",
              "3  товар не пришел, продавец продлил защиту без м...  negative   \n",
              "4      Кофточка голая синтетика, носить не возможно.  negative   \n",
              "\n",
              "                                           tokenized  \n",
              "0  качество плохой пошив ужасный ( горловина напе...  \n",
              "1  товар отдавать другой человек , получать посыл...  \n",
              "2  ужасный синтетика ! тонкий , общий представлят...  \n",
              "3  товар приходить , продавец продлять защита мой...  \n",
              "4     кофточка голый синтетика , носить возможно .\\n  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4jZwNYu95XN"
      },
      "source": [
        "### Векторизация и построение модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iODpObu95XN"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.tokenized, df.sentiment, train_size = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3wRZhu_95XN"
      },
      "source": [
        "##### Ngram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jzLzILGV95XN"
      },
      "source": [
        "def ngram(n_range, analyzer='word'):\n",
        "    count_vectorizer = CountVectorizer(ngram_range=n_range, analyzer=analyzer)\n",
        "    count_x_train = count_vectorizer.fit_transform(x_train)\n",
        "\n",
        "    count_mnb = MultinomialNB()\n",
        "    count_mnb.fit(count_x_train, y_train)\n",
        "\n",
        "    count_vectorizer_test = count_vectorizer.transform(x_test)\n",
        "\n",
        "    count_prediction = count_mnb.predict(count_vectorizer_test)\n",
        "    \n",
        "    return classification_report(y_test, count_prediction, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIkCMr9P95XO"
      },
      "source": [
        "##### Tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEUu3OV795XO"
      },
      "source": [
        "def tfidf(n_range, min_df, max_df, max_features):\n",
        "    tfidf_vectorizer = TfidfVectorizer(\n",
        "        ngram_range=n_range,\n",
        "        max_df=max_df,\n",
        "        min_df=min_df,\n",
        "        max_features=max_features)\n",
        "    tfidf_x_train = tfidf_vectorizer.fit_transform(x_train)\n",
        "\n",
        "    tfidf_mnb = MultinomialNB()\n",
        "    tfidf_mnb.fit(tfidf_x_train, y_train)\n",
        "\n",
        "    tfidf_vectorizer_test = tfidf_vectorizer.transform(x_test)\n",
        "    tfidf_prediction = tfidf_mnb.predict(tfidf_vectorizer_test)\n",
        "    \n",
        "    return classification_report(y_test, tfidf_prediction, output_dict=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usZU3GOm95XP"
      },
      "source": [
        "### Оценка качества модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bVgSoC-I95XP",
        "outputId": "c6ebeb4f-1246-40c1-eec0-a39e3db82589"
      },
      "source": [
        "ngram_max = 4\n",
        "ngram_min = 1\n",
        "min_df_range = [0, 0.01]\n",
        "max_df_range = [0.2, 0.5] #[0.2, 0.25, 0.5]\n",
        "features_range = [10_000, 30_000]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "def calculate_res_count():\n",
        "    for analyzer in ['word', 'char']:\n",
        "        for i in range(ngram_min, ngram_max):\n",
        "            for j in range(i, ngram_max):\n",
        "                all_results.append([ngram((i, j), analyzer),\n",
        "                                   f'Ngrams: ({i},{j})',\n",
        "                                   analyzer])\n",
        "\n",
        "def calculate_res_tfidf():\n",
        "    for i in range(ngram_min, ngram_max):\n",
        "        print(i)\n",
        "        for j in range(i, ngram_max):\n",
        "            for max_d in max_df_range:\n",
        "                for min_d in min_df_range:\n",
        "                    for features_num in features_range:\n",
        "                        all_results.append([tfidf((i, j), min_d, max_d, features_num),\n",
        "                                           f'df\\'s: [{min_d},{max_d}], Features: {features_num}, Ngrams: ({i},{j})',\n",
        "                                           'tfidf'])\n",
        "\n",
        "calculate_res_count()\n",
        "print('50% Done')\n",
        "calculate_res_tfidf()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50% Done\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO1AEf-995XQ"
      },
      "source": [
        "for_df = []\n",
        "\n",
        "for res in all_results:\n",
        "    precision = res[0]['weighted avg']['precision']\n",
        "    recall = res[0]['weighted avg']['recall']\n",
        "    f1 = res[0]['weighted avg']['f1-score']\n",
        "    \n",
        "    params = res[1]\n",
        "    vect = res[2]\n",
        "    \n",
        "    for_df.append({'Precision':precision, \n",
        "                   'Recall':recall, \n",
        "                   'f1-score':f1,\n",
        "                   'Vectorizer': vect,\n",
        "                   'Params':params})\n",
        "\n",
        "final_df = pd.DataFrame(for_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "neD1tQ7x95XQ",
        "outputId": "18b06d2a-d44f-4658-80ca-3534fdde3a14"
      },
      "source": [
        "final_df.sort_values(ascending=False, by='Precision')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>Vectorizer</th>\n",
              "      <th>Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.724491</td>\n",
              "      <td>0.716644</td>\n",
              "      <td>0.718112</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 30000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.724096</td>\n",
              "      <td>0.714600</td>\n",
              "      <td>0.716289</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 30000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.723564</td>\n",
              "      <td>0.715689</td>\n",
              "      <td>0.717065</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 30000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.723354</td>\n",
              "      <td>0.714067</td>\n",
              "      <td>0.715640</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 30000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.723171</td>\n",
              "      <td>0.712978</td>\n",
              "      <td>0.714850</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 10000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.722553</td>\n",
              "      <td>0.711156</td>\n",
              "      <td>0.713110</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 10000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.721702</td>\n",
              "      <td>0.711511</td>\n",
              "      <td>0.713319</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 10000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.721531</td>\n",
              "      <td>0.710222</td>\n",
              "      <td>0.712076</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 10000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.718697</td>\n",
              "      <td>0.716533</td>\n",
              "      <td>0.716727</td>\n",
              "      <td>word</td>\n",
              "      <td>Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.716710</td>\n",
              "      <td>0.716489</td>\n",
              "      <td>0.716176</td>\n",
              "      <td>word</td>\n",
              "      <td>Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.709944</td>\n",
              "      <td>0.701822</td>\n",
              "      <td>0.703215</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 10000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.709495</td>\n",
              "      <td>0.703244</td>\n",
              "      <td>0.703986</td>\n",
              "      <td>word</td>\n",
              "      <td>Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.709488</td>\n",
              "      <td>0.701956</td>\n",
              "      <td>0.703267</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 30000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.708742</td>\n",
              "      <td>0.701422</td>\n",
              "      <td>0.702674</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 30000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.708608</td>\n",
              "      <td>0.701067</td>\n",
              "      <td>0.702343</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 10000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.704757</td>\n",
              "      <td>0.689933</td>\n",
              "      <td>0.692990</td>\n",
              "      <td>char</td>\n",
              "      <td>Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.697793</td>\n",
              "      <td>0.681378</td>\n",
              "      <td>0.684781</td>\n",
              "      <td>char</td>\n",
              "      <td>Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.694208</td>\n",
              "      <td>0.676911</td>\n",
              "      <td>0.680443</td>\n",
              "      <td>char</td>\n",
              "      <td>Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>0.693733</td>\n",
              "      <td>0.686200</td>\n",
              "      <td>0.688095</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 30000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.693733</td>\n",
              "      <td>0.686200</td>\n",
              "      <td>0.688095</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 30000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>0.693246</td>\n",
              "      <td>0.683444</td>\n",
              "      <td>0.685718</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 30000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>0.693246</td>\n",
              "      <td>0.683444</td>\n",
              "      <td>0.685718</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 30000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.691734</td>\n",
              "      <td>0.677689</td>\n",
              "      <td>0.680846</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 10000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>0.691734</td>\n",
              "      <td>0.677689</td>\n",
              "      <td>0.680846</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 10000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>0.689464</td>\n",
              "      <td>0.673244</td>\n",
              "      <td>0.676490</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 10000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>0.689464</td>\n",
              "      <td>0.673244</td>\n",
              "      <td>0.676490</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 10000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.687900</td>\n",
              "      <td>0.688156</td>\n",
              "      <td>0.687696</td>\n",
              "      <td>word</td>\n",
              "      <td>Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.684905</td>\n",
              "      <td>0.671000</td>\n",
              "      <td>0.673240</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 30000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.684905</td>\n",
              "      <td>0.671000</td>\n",
              "      <td>0.673240</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 10000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.684852</td>\n",
              "      <td>0.671067</td>\n",
              "      <td>0.673427</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 10000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.684852</td>\n",
              "      <td>0.671067</td>\n",
              "      <td>0.673427</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 30000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.683498</td>\n",
              "      <td>0.669844</td>\n",
              "      <td>0.671899</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 10000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.683498</td>\n",
              "      <td>0.669844</td>\n",
              "      <td>0.671899</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 30000, Ngrams: (1,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.683381</td>\n",
              "      <td>0.669933</td>\n",
              "      <td>0.672111</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 10000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.683381</td>\n",
              "      <td>0.669933</td>\n",
              "      <td>0.672111</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 30000, Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.682710</td>\n",
              "      <td>0.670756</td>\n",
              "      <td>0.673409</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 30000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.682710</td>\n",
              "      <td>0.670756</td>\n",
              "      <td>0.673409</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 10000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.681076</td>\n",
              "      <td>0.683089</td>\n",
              "      <td>0.681767</td>\n",
              "      <td>word</td>\n",
              "      <td>Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.679969</td>\n",
              "      <td>0.668822</td>\n",
              "      <td>0.671193</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 10000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.679969</td>\n",
              "      <td>0.668822</td>\n",
              "      <td>0.671193</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 30000, Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.664710</td>\n",
              "      <td>0.646733</td>\n",
              "      <td>0.650506</td>\n",
              "      <td>char</td>\n",
              "      <td>Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.658019</td>\n",
              "      <td>0.637044</td>\n",
              "      <td>0.641067</td>\n",
              "      <td>char</td>\n",
              "      <td>Ngrams: (1,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.547133</td>\n",
              "      <td>0.550509</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 10000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.547133</td>\n",
              "      <td>0.550509</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 10000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.617671</td>\n",
              "      <td>0.565533</td>\n",
              "      <td>0.571178</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.5], Features: 30000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.617671</td>\n",
              "      <td>0.565533</td>\n",
              "      <td>0.571178</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0,0.2], Features: 30000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.612147</td>\n",
              "      <td>0.589133</td>\n",
              "      <td>0.594417</td>\n",
              "      <td>word</td>\n",
              "      <td>Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>0.603629</td>\n",
              "      <td>0.498244</td>\n",
              "      <td>0.490203</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 30000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>0.603629</td>\n",
              "      <td>0.498244</td>\n",
              "      <td>0.490203</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 10000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>0.603629</td>\n",
              "      <td>0.498244</td>\n",
              "      <td>0.490203</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 10000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>0.603629</td>\n",
              "      <td>0.498244</td>\n",
              "      <td>0.490203</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 30000, Ngrams: (2,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>0.603610</td>\n",
              "      <td>0.498222</td>\n",
              "      <td>0.490190</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 30000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>0.603610</td>\n",
              "      <td>0.498222</td>\n",
              "      <td>0.490190</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 10000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.603610</td>\n",
              "      <td>0.498222</td>\n",
              "      <td>0.490190</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 30000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.603610</td>\n",
              "      <td>0.498222</td>\n",
              "      <td>0.490190</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 10000, Ngrams: (2,2)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.563886</td>\n",
              "      <td>0.534889</td>\n",
              "      <td>0.536473</td>\n",
              "      <td>char</td>\n",
              "      <td>Ngrams: (1,1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>0.344021</td>\n",
              "      <td>0.336822</td>\n",
              "      <td>0.182904</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 10000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>0.344021</td>\n",
              "      <td>0.336822</td>\n",
              "      <td>0.182904</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.2], Features: 30000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>0.344021</td>\n",
              "      <td>0.336822</td>\n",
              "      <td>0.182904</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 10000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>0.344021</td>\n",
              "      <td>0.336822</td>\n",
              "      <td>0.182904</td>\n",
              "      <td>tfidf</td>\n",
              "      <td>df's: [0.01,0.5], Features: 30000, Ngrams: (3,3)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Precision    Recall  f1-score Vectorizer  \\\n",
              "25   0.724491  0.716644  0.718112      tfidf   \n",
              "33   0.724096  0.714600  0.716289      tfidf   \n",
              "21   0.723564  0.715689  0.717065      tfidf   \n",
              "29   0.723354  0.714067  0.715640      tfidf   \n",
              "24   0.723171  0.712978  0.714850      tfidf   \n",
              "32   0.722553  0.711156  0.713110      tfidf   \n",
              "20   0.721702  0.711511  0.713319      tfidf   \n",
              "28   0.721531  0.710222  0.712076      tfidf   \n",
              "1    0.718697  0.716533  0.716727       word   \n",
              "2    0.716710  0.716489  0.716176       word   \n",
              "16   0.709944  0.701822  0.703215      tfidf   \n",
              "0    0.709495  0.703244  0.703986       word   \n",
              "17   0.709488  0.701956  0.703267      tfidf   \n",
              "13   0.708742  0.701422  0.702674      tfidf   \n",
              "12   0.708608  0.701067  0.702343      tfidf   \n",
              "11   0.704757  0.689933  0.692990       char   \n",
              "10   0.697793  0.681378  0.684781       char   \n",
              "8    0.694208  0.676911  0.680443       char   \n",
              "41   0.693733  0.686200  0.688095      tfidf   \n",
              "37   0.693733  0.686200  0.688095      tfidf   \n",
              "45   0.693246  0.683444  0.685718      tfidf   \n",
              "49   0.693246  0.683444  0.685718      tfidf   \n",
              "36   0.691734  0.677689  0.680846      tfidf   \n",
              "40   0.691734  0.677689  0.680846      tfidf   \n",
              "44   0.689464  0.673244  0.676490      tfidf   \n",
              "48   0.689464  0.673244  0.676490      tfidf   \n",
              "3    0.687900  0.688156  0.687696       word   \n",
              "35   0.684905  0.671000  0.673240      tfidf   \n",
              "34   0.684905  0.671000  0.673240      tfidf   \n",
              "26   0.684852  0.671067  0.673427      tfidf   \n",
              "27   0.684852  0.671067  0.673427      tfidf   \n",
              "30   0.683498  0.669844  0.671899      tfidf   \n",
              "31   0.683498  0.669844  0.671899      tfidf   \n",
              "22   0.683381  0.669933  0.672111      tfidf   \n",
              "23   0.683381  0.669933  0.672111      tfidf   \n",
              "19   0.682710  0.670756  0.673409      tfidf   \n",
              "18   0.682710  0.670756  0.673409      tfidf   \n",
              "4    0.681076  0.683089  0.681767       word   \n",
              "14   0.679969  0.668822  0.671193      tfidf   \n",
              "15   0.679969  0.668822  0.671193      tfidf   \n",
              "9    0.664710  0.646733  0.650506       char   \n",
              "7    0.658019  0.637044  0.641067       char   \n",
              "56   0.618263  0.547133  0.550509      tfidf   \n",
              "52   0.618263  0.547133  0.550509      tfidf   \n",
              "57   0.617671  0.565533  0.571178      tfidf   \n",
              "53   0.617671  0.565533  0.571178      tfidf   \n",
              "5    0.612147  0.589133  0.594417       word   \n",
              "51   0.603629  0.498244  0.490203      tfidf   \n",
              "50   0.603629  0.498244  0.490203      tfidf   \n",
              "46   0.603629  0.498244  0.490203      tfidf   \n",
              "47   0.603629  0.498244  0.490203      tfidf   \n",
              "43   0.603610  0.498222  0.490190      tfidf   \n",
              "42   0.603610  0.498222  0.490190      tfidf   \n",
              "39   0.603610  0.498222  0.490190      tfidf   \n",
              "38   0.603610  0.498222  0.490190      tfidf   \n",
              "6    0.563886  0.534889  0.536473       char   \n",
              "54   0.344021  0.336822  0.182904      tfidf   \n",
              "55   0.344021  0.336822  0.182904      tfidf   \n",
              "58   0.344021  0.336822  0.182904      tfidf   \n",
              "59   0.344021  0.336822  0.182904      tfidf   \n",
              "\n",
              "                                              Params  \n",
              "25     df's: [0,0.5], Features: 30000, Ngrams: (1,2)  \n",
              "33     df's: [0,0.5], Features: 30000, Ngrams: (1,3)  \n",
              "21     df's: [0,0.2], Features: 30000, Ngrams: (1,2)  \n",
              "29     df's: [0,0.2], Features: 30000, Ngrams: (1,3)  \n",
              "24     df's: [0,0.5], Features: 10000, Ngrams: (1,2)  \n",
              "32     df's: [0,0.5], Features: 10000, Ngrams: (1,3)  \n",
              "20     df's: [0,0.2], Features: 10000, Ngrams: (1,2)  \n",
              "28     df's: [0,0.2], Features: 10000, Ngrams: (1,3)  \n",
              "1                                      Ngrams: (1,2)  \n",
              "2                                      Ngrams: (1,3)  \n",
              "16     df's: [0,0.5], Features: 10000, Ngrams: (1,1)  \n",
              "0                                      Ngrams: (1,1)  \n",
              "17     df's: [0,0.5], Features: 30000, Ngrams: (1,1)  \n",
              "13     df's: [0,0.2], Features: 30000, Ngrams: (1,1)  \n",
              "12     df's: [0,0.2], Features: 10000, Ngrams: (1,1)  \n",
              "11                                     Ngrams: (3,3)  \n",
              "10                                     Ngrams: (2,3)  \n",
              "8                                      Ngrams: (1,3)  \n",
              "41     df's: [0,0.5], Features: 30000, Ngrams: (2,2)  \n",
              "37     df's: [0,0.2], Features: 30000, Ngrams: (2,2)  \n",
              "45     df's: [0,0.2], Features: 30000, Ngrams: (2,3)  \n",
              "49     df's: [0,0.5], Features: 30000, Ngrams: (2,3)  \n",
              "36     df's: [0,0.2], Features: 10000, Ngrams: (2,2)  \n",
              "40     df's: [0,0.5], Features: 10000, Ngrams: (2,2)  \n",
              "44     df's: [0,0.2], Features: 10000, Ngrams: (2,3)  \n",
              "48     df's: [0,0.5], Features: 10000, Ngrams: (2,3)  \n",
              "3                                      Ngrams: (2,2)  \n",
              "35  df's: [0.01,0.5], Features: 30000, Ngrams: (1,3)  \n",
              "34  df's: [0.01,0.5], Features: 10000, Ngrams: (1,3)  \n",
              "26  df's: [0.01,0.5], Features: 10000, Ngrams: (1,2)  \n",
              "27  df's: [0.01,0.5], Features: 30000, Ngrams: (1,2)  \n",
              "30  df's: [0.01,0.2], Features: 10000, Ngrams: (1,3)  \n",
              "31  df's: [0.01,0.2], Features: 30000, Ngrams: (1,3)  \n",
              "22  df's: [0.01,0.2], Features: 10000, Ngrams: (1,2)  \n",
              "23  df's: [0.01,0.2], Features: 30000, Ngrams: (1,2)  \n",
              "19  df's: [0.01,0.5], Features: 30000, Ngrams: (1,1)  \n",
              "18  df's: [0.01,0.5], Features: 10000, Ngrams: (1,1)  \n",
              "4                                      Ngrams: (2,3)  \n",
              "14  df's: [0.01,0.2], Features: 10000, Ngrams: (1,1)  \n",
              "15  df's: [0.01,0.2], Features: 30000, Ngrams: (1,1)  \n",
              "9                                      Ngrams: (2,2)  \n",
              "7                                      Ngrams: (1,2)  \n",
              "56     df's: [0,0.5], Features: 10000, Ngrams: (3,3)  \n",
              "52     df's: [0,0.2], Features: 10000, Ngrams: (3,3)  \n",
              "57     df's: [0,0.5], Features: 30000, Ngrams: (3,3)  \n",
              "53     df's: [0,0.2], Features: 30000, Ngrams: (3,3)  \n",
              "5                                      Ngrams: (3,3)  \n",
              "51  df's: [0.01,0.5], Features: 30000, Ngrams: (2,3)  \n",
              "50  df's: [0.01,0.5], Features: 10000, Ngrams: (2,3)  \n",
              "46  df's: [0.01,0.2], Features: 10000, Ngrams: (2,3)  \n",
              "47  df's: [0.01,0.2], Features: 30000, Ngrams: (2,3)  \n",
              "43  df's: [0.01,0.5], Features: 30000, Ngrams: (2,2)  \n",
              "42  df's: [0.01,0.5], Features: 10000, Ngrams: (2,2)  \n",
              "39  df's: [0.01,0.2], Features: 30000, Ngrams: (2,2)  \n",
              "38  df's: [0.01,0.2], Features: 10000, Ngrams: (2,2)  \n",
              "6                                      Ngrams: (1,1)  \n",
              "54  df's: [0.01,0.2], Features: 10000, Ngrams: (3,3)  \n",
              "55  df's: [0.01,0.2], Features: 30000, Ngrams: (3,3)  \n",
              "58  df's: [0.01,0.5], Features: 10000, Ngrams: (3,3)  \n",
              "59  df's: [0.01,0.5], Features: 30000, Ngrams: (3,3)  "
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Qgzc0IIq95XQ",
        "outputId": "496c6f81-6b18-4658-b4e0-8436fa7c03a6"
      },
      "source": [
        "print(final_df.to_string())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Precision    Recall  f1-score Vectorizer                                            Params\n",
            "0    0.709495  0.703244  0.703986       word                                     Ngrams: (1,1)\n",
            "1    0.718697  0.716533  0.716727       word                                     Ngrams: (1,2)\n",
            "2    0.716710  0.716489  0.716176       word                                     Ngrams: (1,3)\n",
            "3    0.687900  0.688156  0.687696       word                                     Ngrams: (2,2)\n",
            "4    0.681076  0.683089  0.681767       word                                     Ngrams: (2,3)\n",
            "5    0.612147  0.589133  0.594417       word                                     Ngrams: (3,3)\n",
            "6    0.563886  0.534889  0.536473       char                                     Ngrams: (1,1)\n",
            "7    0.658019  0.637044  0.641067       char                                     Ngrams: (1,2)\n",
            "8    0.694208  0.676911  0.680443       char                                     Ngrams: (1,3)\n",
            "9    0.664710  0.646733  0.650506       char                                     Ngrams: (2,2)\n",
            "10   0.697793  0.681378  0.684781       char                                     Ngrams: (2,3)\n",
            "11   0.704757  0.689933  0.692990       char                                     Ngrams: (3,3)\n",
            "12   0.708608  0.701067  0.702343      tfidf     df's: [0,0.2], Features: 10000, Ngrams: (1,1)\n",
            "13   0.708742  0.701422  0.702674      tfidf     df's: [0,0.2], Features: 30000, Ngrams: (1,1)\n",
            "14   0.679969  0.668822  0.671193      tfidf  df's: [0.01,0.2], Features: 10000, Ngrams: (1,1)\n",
            "15   0.679969  0.668822  0.671193      tfidf  df's: [0.01,0.2], Features: 30000, Ngrams: (1,1)\n",
            "16   0.709944  0.701822  0.703215      tfidf     df's: [0,0.5], Features: 10000, Ngrams: (1,1)\n",
            "17   0.709488  0.701956  0.703267      tfidf     df's: [0,0.5], Features: 30000, Ngrams: (1,1)\n",
            "18   0.682710  0.670756  0.673409      tfidf  df's: [0.01,0.5], Features: 10000, Ngrams: (1,1)\n",
            "19   0.682710  0.670756  0.673409      tfidf  df's: [0.01,0.5], Features: 30000, Ngrams: (1,1)\n",
            "20   0.721702  0.711511  0.713319      tfidf     df's: [0,0.2], Features: 10000, Ngrams: (1,2)\n",
            "21   0.723564  0.715689  0.717065      tfidf     df's: [0,0.2], Features: 30000, Ngrams: (1,2)\n",
            "22   0.683381  0.669933  0.672111      tfidf  df's: [0.01,0.2], Features: 10000, Ngrams: (1,2)\n",
            "23   0.683381  0.669933  0.672111      tfidf  df's: [0.01,0.2], Features: 30000, Ngrams: (1,2)\n",
            "24   0.723171  0.712978  0.714850      tfidf     df's: [0,0.5], Features: 10000, Ngrams: (1,2)\n",
            "25   0.724491  0.716644  0.718112      tfidf     df's: [0,0.5], Features: 30000, Ngrams: (1,2)\n",
            "26   0.684852  0.671067  0.673427      tfidf  df's: [0.01,0.5], Features: 10000, Ngrams: (1,2)\n",
            "27   0.684852  0.671067  0.673427      tfidf  df's: [0.01,0.5], Features: 30000, Ngrams: (1,2)\n",
            "28   0.721531  0.710222  0.712076      tfidf     df's: [0,0.2], Features: 10000, Ngrams: (1,3)\n",
            "29   0.723354  0.714067  0.715640      tfidf     df's: [0,0.2], Features: 30000, Ngrams: (1,3)\n",
            "30   0.683498  0.669844  0.671899      tfidf  df's: [0.01,0.2], Features: 10000, Ngrams: (1,3)\n",
            "31   0.683498  0.669844  0.671899      tfidf  df's: [0.01,0.2], Features: 30000, Ngrams: (1,3)\n",
            "32   0.722553  0.711156  0.713110      tfidf     df's: [0,0.5], Features: 10000, Ngrams: (1,3)\n",
            "33   0.724096  0.714600  0.716289      tfidf     df's: [0,0.5], Features: 30000, Ngrams: (1,3)\n",
            "34   0.684905  0.671000  0.673240      tfidf  df's: [0.01,0.5], Features: 10000, Ngrams: (1,3)\n",
            "35   0.684905  0.671000  0.673240      tfidf  df's: [0.01,0.5], Features: 30000, Ngrams: (1,3)\n",
            "36   0.691734  0.677689  0.680846      tfidf     df's: [0,0.2], Features: 10000, Ngrams: (2,2)\n",
            "37   0.693733  0.686200  0.688095      tfidf     df's: [0,0.2], Features: 30000, Ngrams: (2,2)\n",
            "38   0.603610  0.498222  0.490190      tfidf  df's: [0.01,0.2], Features: 10000, Ngrams: (2,2)\n",
            "39   0.603610  0.498222  0.490190      tfidf  df's: [0.01,0.2], Features: 30000, Ngrams: (2,2)\n",
            "40   0.691734  0.677689  0.680846      tfidf     df's: [0,0.5], Features: 10000, Ngrams: (2,2)\n",
            "41   0.693733  0.686200  0.688095      tfidf     df's: [0,0.5], Features: 30000, Ngrams: (2,2)\n",
            "42   0.603610  0.498222  0.490190      tfidf  df's: [0.01,0.5], Features: 10000, Ngrams: (2,2)\n",
            "43   0.603610  0.498222  0.490190      tfidf  df's: [0.01,0.5], Features: 30000, Ngrams: (2,2)\n",
            "44   0.689464  0.673244  0.676490      tfidf     df's: [0,0.2], Features: 10000, Ngrams: (2,3)\n",
            "45   0.693246  0.683444  0.685718      tfidf     df's: [0,0.2], Features: 30000, Ngrams: (2,3)\n",
            "46   0.603629  0.498244  0.490203      tfidf  df's: [0.01,0.2], Features: 10000, Ngrams: (2,3)\n",
            "47   0.603629  0.498244  0.490203      tfidf  df's: [0.01,0.2], Features: 30000, Ngrams: (2,3)\n",
            "48   0.689464  0.673244  0.676490      tfidf     df's: [0,0.5], Features: 10000, Ngrams: (2,3)\n",
            "49   0.693246  0.683444  0.685718      tfidf     df's: [0,0.5], Features: 30000, Ngrams: (2,3)\n",
            "50   0.603629  0.498244  0.490203      tfidf  df's: [0.01,0.5], Features: 10000, Ngrams: (2,3)\n",
            "51   0.603629  0.498244  0.490203      tfidf  df's: [0.01,0.5], Features: 30000, Ngrams: (2,3)\n",
            "52   0.618263  0.547133  0.550509      tfidf     df's: [0,0.2], Features: 10000, Ngrams: (3,3)\n",
            "53   0.617671  0.565533  0.571178      tfidf     df's: [0,0.2], Features: 30000, Ngrams: (3,3)\n",
            "54   0.344021  0.336822  0.182904      tfidf  df's: [0.01,0.2], Features: 10000, Ngrams: (3,3)\n",
            "55   0.344021  0.336822  0.182904      tfidf  df's: [0.01,0.2], Features: 30000, Ngrams: (3,3)\n",
            "56   0.618263  0.547133  0.550509      tfidf     df's: [0,0.5], Features: 10000, Ngrams: (3,3)\n",
            "57   0.617671  0.565533  0.571178      tfidf     df's: [0,0.5], Features: 30000, Ngrams: (3,3)\n",
            "58   0.344021  0.336822  0.182904      tfidf  df's: [0.01,0.5], Features: 10000, Ngrams: (3,3)\n",
            "59   0.344021  0.336822  0.182904      tfidf  df's: [0.01,0.5], Features: 30000, Ngrams: (3,3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMI1WoQF-Col"
      },
      "source": [
        "### Выводы и обьяснения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6tLcjkG95XR"
      },
      "source": [
        "Так как датасет представляет собой набор отзывов о товарах, где каждый отзыв является набором из нескольких коротких предложений с частовстречающейся лингвистичекой конструкцией прилагательное-существительное или существительное-прилагательное (например: *товар бракованный*, *плохой продавец*, *долгая доставка*), то большая верхняя граница Ngram скорее усугубит обучение.\n",
        "\n",
        "Как видно из таблицы параметр Features крайне слабо сказывается на результатах, а в большинстве случаев вовсе никак не влияет на них.\n",
        "\n",
        "Возможных значений параметра min_df всего 2 так как при увеличении даже на 0.01 результаты предсказания падают значительно.\n",
        "\n",
        "Увеличение параметра max_df в свою очередь улучшает результаты. По видимому это происходит из-за того, что во многих отзывах часто встречаются такие слова как *товар*, *качество*, *доставка*, которые сами по себе не несут отрицательного или положительного контекста и гораздо важнее какой эпитет с ними связан.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QYTwyMtWhAZ"
      },
      "source": [
        "## Задание 5.2 Регулярные выражения\n",
        "\n",
        "Регулярные выражения - способ поиска и анализа строк. Например, можно понять, какие даты в наборе строк представлены в формате DD/MM/YYYY, а какие - в других форматах. \n",
        "\n",
        "Или бывает, например, что перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
        "\n",
        "Навык полезный, давайте в нём тоже потренируемся.\n",
        "\n",
        "Для работы с регулярными выражениями есть библиотека **re**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaUW5S4gWhAb"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6aYh7Osl8xr"
      },
      "source": [
        "В регулярных выражениях, кроме привычных символов-букв, есть специальные символы:\n",
        "* **?а** - ноль или один символ **а**\n",
        "* **+а** - один или более символов **а**\n",
        "* **\\*а** - ноль или более символов **а** (не путать с +)\n",
        "* **.** - любое количество любого символа\n",
        "\n",
        "Пример:\n",
        "Выражению \\*a?b. соответствуют последовательности a, ab, abc, aa, aac НО НЕ abb!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zOFFA3l_KQ"
      },
      "source": [
        "Рассмотрим подробно несколько наиболее полезных функций:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbJrUpARWhAd"
      },
      "source": [
        "### findall\n",
        "возвращает список всех найденных непересекающихся совпадений.\n",
        "\n",
        "Регулярное выражение **ab+c.**: \n",
        "* **a** - просто символ **a**\n",
        "* **b+** - один или более символов **b**\n",
        "* **c** - просто символ **c**\n",
        "* **.** - любой символ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2athHzKuWhAd",
        "outputId": "ff2d7b25-31bb-4877-bd50-95442e6a8158"
      },
      "source": [
        "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abcd', 'abca']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9FpIw5RWhAf"
      },
      "source": [
        "Вопрос на внимательность: почему нет abcx?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5ttzoxEWhAg"
      },
      "source": [
        "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR2AEq3WhAg",
        "outputId": "d06f56e5-a643-4264-c1f5-0144a3b62e47"
      },
      "source": [
        "t1 = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit'\n",
        "re.findall(r\"\\b\\w{1,2}\", t1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Lo', 'ip', 'do', 'si', 'am', 'co', 'ad', 'el']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI18l-l9WhAk"
      },
      "source": [
        "### split\n",
        "разделяет строку по заданному шаблону\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVKdRoc1WhAl",
        "outputId": "78b5d289-8e8c-4621-fe3c-34aa130c727c"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['itsy', ' bitsy', ' teenie', ' weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10u5efuSWhAm"
      },
      "source": [
        "можно указать максимальное количество разбиений"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U9EQZMwWhAn",
        "outputId": "45699604-9950-4185-cd4f-0e3ad6655629"
      },
      "source": [
        "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit=2) \n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['itsy', ' bitsy', ' teenie, weenie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EMcMyflWhAp"
      },
      "source": [
        "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVgPSjEOWhAp",
        "outputId": "737fecbc-9131-44cf-da02-3f9c696db6df"
      },
      "source": [
        "t2 = ' sed do eiusmod. tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam.'\n",
        "\n",
        "re.split(r'\\.', t2, maxsplit=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[' sed do eiusmod',\n",
              " ' tempor incididunt ut labore et dolore magna aliqua',\n",
              " ' Ut enim ad minim veniam.']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wrEGqBSWhAr"
      },
      "source": [
        "### sub\n",
        "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
        "\n",
        "параметры: (pattern, repl, string)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az3KxKWwWhAr",
        "outputId": "93f260be-ce79-405c-b21a-5ca8345ff4b7"
      },
      "source": [
        "result = re.sub('a', 'b', 'abcabc')\n",
        "print (result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bbcbbc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD0n7_HPWhAt"
      },
      "source": [
        "**Задание**: напишите регулярное выражение, которое позволит заменить все цифры в строке на \"DIG\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_Sdu7xlWhAu",
        "outputId": "6cb41dd2-bb4c-4b50-ee5e-ace9fd59df9d"
      },
      "source": [
        "t3 = ' quis1 nostrud exerc4itation3 ul0lamco laboris nis7i ut 321'\n",
        "re.sub(r'\\d', 'DIG', t3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' quisDIG nostrud exercDIGitationDIG ulDIGlamco laboris nisDIGi ut DIGDIGDIG'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8__oi1PWhAv"
      },
      "source": [
        "**Задание**: напишите  регулярное выражение, которое позволит убрать url из строки."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwNS9zt4WhAv",
        "outputId": "389bc576-ccba-4966-8902-2d19bc54d6fc"
      },
      "source": [
        "t4 = '  aliquip ex ea commodo consequat. https://abc.bla.bla.shouldiblamecaching.com/a/asdnv/  Duis aute irure dolor '\n",
        "re.sub(r'http[s]?://[\\w.]+[/\\w]+/?', '', t4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'  aliquip ex ea commodo consequat.   Duis aute irure dolor '"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gStgBJy2WhAx"
      },
      "source": [
        "### compile\n",
        "компилирует регулярное выражение в отдельный объект"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JstTupisWhAy",
        "outputId": "f60e13a6-9d93-46e5-f329-620f6072715f"
      },
      "source": [
        "# Пример: построение списка всех слов строки:\n",
        "prog = re.compile('[А-Яа-яё\\-]+')\n",
        "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEXc3G0WhA2"
      },
      "source": [
        "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFvnIWbUWhA2",
        "outputId": "19e02341-0f86-40bd-a958-5fe4751728fb"
      },
      "source": [
        "t5 = 'in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'\n",
        "re.compile(r'\\w{4,}').findall(t5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['reprehenderit',\n",
              " 'voluptate',\n",
              " 'velit',\n",
              " 'esse',\n",
              " 'cillum',\n",
              " 'dolore',\n",
              " 'fugiat',\n",
              " 'nulla',\n",
              " 'pariatur',\n",
              " 'Excepteur',\n",
              " 'sint',\n",
              " 'occaecat',\n",
              " 'cupidatat',\n",
              " 'proident',\n",
              " 'sunt',\n",
              " 'culpa',\n",
              " 'officia',\n",
              " 'deserunt',\n",
              " 'mollit',\n",
              " 'anim',\n",
              " 'laborum']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQDNZ3HQWhA3"
      },
      "source": [
        "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
        "\n",
        "```\n",
        "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlcWBoKM95XV",
        "outputId": "9d1f0ae0-7cd5-40d7-db07-013e3c045e59"
      },
      "source": [
        "t6 = 'abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz'\n",
        "re.compile(r'@[\\w.]+').findall(t6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['@gmail.com', '@test.in', '@analyticsvidhya.com', '@rest.biz']"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rGp787n95XV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}